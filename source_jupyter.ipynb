{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an abundance of data. Although not all of it might be used, it's still important to inspect each dataset. Let's start with the tournament teams, tournament seeding, and regular season results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MTeams.csv\")\n",
    "\n",
    "print(\"Men's tournament teams\")\n",
    "print(teams_m.head())\n",
    "\n",
    "teams_w = pd.read_csv(\"/kaggle/input/march-madness-2025/WTeams.csv\")\n",
    "\n",
    "print(\"\\nWomen's tournament teams\")\n",
    "print(teams_w.head())\n",
    "\n",
    "seeding_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MNCAATourneySeeds.csv\")\n",
    "\n",
    "print(\"\\nMen's tournament seeds\")\n",
    "print(seeding_m.head())\n",
    "\n",
    "seeding_w = pd.read_csv(\"/kaggle/input/march-madness-2025/WNCAATourneySeeds.csv\")\n",
    "\n",
    "print(\"\\nWomen's tournament seeds\")\n",
    "print(seeding_w.head())\n",
    "\n",
    "tournament_compact_results_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MNCAATourneyCompactResults.csv\")\n",
    "\n",
    "print(\"\\nMen's Compact Tournament Results\")\n",
    "print(tournament_compact_results_m.head())\n",
    "\n",
    "tournament_compact_results_w = pd.read_csv(\"/kaggle/input/march-madness-2025/WNCAATourneyCompactResults.csv\")\n",
    "\n",
    "print(\"\\nWomen's Compact Tournament Results\")\n",
    "print(tournament_compact_results_w.head())\n",
    "\n",
    "tournament_detailed_results_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MNCAATourneyDetailedResults.csv\")\n",
    "\n",
    "print(\"\\nMen's Detailed Tournament Results\")\n",
    "print(tournament_detailed_results_m.head())\n",
    "\n",
    "tournament_detailed_results_w = pd.read_csv(\"/kaggle/input/march-madness-2025//WNCAATourneyDetailedResults.csv\")\n",
    "\n",
    "print(\"\\nWomen's Detailed Tournament Results\")\n",
    "print(tournament_detailed_results_w.head())\n",
    "\n",
    "regular_season_compact_results_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MRegularSeasonCompactResults.csv\")\n",
    "\n",
    "print(\"\\nMen's Regular Season Compact Results\")\n",
    "print(regular_season_compact_results_m.head())\n",
    "\n",
    "regular_season_compact_results_w = pd.read_csv(\"/kaggle/input/march-madness-2025/WRegularSeasonCompactResults.csv\")\n",
    "\n",
    "print(\"\\nWomen's Regular Season Compact Results\")\n",
    "print(regular_season_compact_results_w.head())\n",
    "\n",
    "regular_season_detailed_results_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MRegularSeasonDetailedResults.csv\")\n",
    "\n",
    "print(\"\\nMen's Detailed Season Compact Results\")\n",
    "print(regular_season_detailed_results_m.head())\n",
    "\n",
    "regular_season_detailed_results_w = pd.read_csv(\"/kaggle/input/march-madness-2025/WRegularSeasonDetailedResults.csv\")\n",
    "\n",
    "print(\"\\nMen's Detailed Season Compact Results\")\n",
    "print(regular_season_detailed_results_w.head())\n",
    "\n",
    "conferences_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MTeamConferences.csv\")\n",
    "\n",
    "print(\"\\nMen's Team Conferences\")\n",
    "print(conferences_m.head())\n",
    "\n",
    "conferences_w = pd.read_csv(\"/kaggle/input/march-madness-2025/WTeamConferences.csv\")\n",
    "\n",
    "print(\"\\nWomen's Team Conferences\")\n",
    "print(conferences_w.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['seed'] = df['Seed'].apply(lambda x: int(x[1:3]))\n",
    "    df.drop(columns=['Seed'], inplace=True)\n",
    "    return df\n",
    "\n",
    "seeding_by_season_m = get_seed(seeding_m)\n",
    "seeding_by_season_w = get_seed(seeding_w)\n",
    "\n",
    "print(seeding_by_season_m.head())\n",
    "print(seeding_by_season_w.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_submission(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Filter rows where WTeamID < LTeamID and select relevant columns\n",
    "    base1 = df.loc[df['WTeamID'] < df['LTeamID'], ['Season', 'WTeamID', 'LTeamID']]\n",
    "    submission1 = base1.assign(\n",
    "        ID=base1['Season'].astype(str) + \"_\" + base1['WTeamID'].astype(str) + \"_\" + base1['LTeamID'].astype(str),\n",
    "        pred=1\n",
    "    )\n",
    "    \n",
    "    # Filter rows where WTeamID > LTeamID and select relevant columns\n",
    "    base2 = df.loc[df['WTeamID'] > df['LTeamID'], ['Season', 'WTeamID', 'LTeamID']]\n",
    "    submission2 = base2.assign(\n",
    "        ID=base2['Season'].astype(str) + \"_\" + base2['LTeamID'].astype(str) + \"_\" + base2['WTeamID'].astype(str),\n",
    "        pred=0\n",
    "    )\n",
    "    \n",
    "    # Combine and shuffle the submission formats\n",
    "    submission_combined = pd.concat([submission1, submission2]).sample(frac=1.0, replace=False).reset_index(drop=True)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    return submission_combined.drop(columns=['Season', 'WTeamID', 'LTeamID'])\n",
    "\n",
    "# Create submissions for men's and women's data\n",
    "submission_base_m = create_base_submission(tournament_compact_results_m)\n",
    "submission_base_w = create_base_submission(tournament_compact_results_w)\n",
    "\n",
    "# Combine submissions\n",
    "submission_base_combined = pd.concat([submission_base_m, submission_base_w])\n",
    "\n",
    "# Display the final submission\n",
    "display(submission_base_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are to be able to extract the win loss records of each season of each team. We need to the margin of victory, strength of schedule, and simple rating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_of_victory(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # First calculate MOV for each game\n",
    "    df_with_mov = df.copy()\n",
    "    df_with_mov['MOV'] = df_with_mov['WScore'] - df_with_mov['LScore']\n",
    "\n",
    "    # Create dataframe for winning teams\n",
    "    winners = df_with_mov[['Season', 'WTeamID', 'MOV']].rename(columns={'WTeamID': 'TeamID'})\n",
    "    winners['Win'] = 1\n",
    "    winners['Loss'] = 0\n",
    "\n",
    "    # Create dataframe for losing teams (negative MOV)\n",
    "    losers = df_with_mov[['Season', 'LTeamID', 'MOV']].rename(columns={'LTeamID': 'TeamID'})\n",
    "    losers['MOV'] = -losers['MOV']\n",
    "    losers['Win'] = 0\n",
    "    losers['Loss'] = 1\n",
    "\n",
    "    # Combine both dataframes\n",
    "    all_teams = pd.concat([winners, losers])\n",
    "\n",
    "    # Group by Season and TeamID to get aggregate stats\n",
    "    team_mov = all_teams.groupby(['Season', 'TeamID']).agg(\n",
    "        avg_MOV=('MOV', 'mean'),\n",
    "        total_MOV=('MOV', 'sum'),\n",
    "        games_played=('MOV', 'count'),\n",
    "        wins=('Win', 'sum'),\n",
    "        losses=('Loss', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate winning percentage\n",
    "    team_mov['win_pct'] = team_mov['wins'] / team_mov['games_played']\n",
    "\n",
    "    return team_mov\n",
    "\n",
    "mov_m = margin_of_victory(regular_season_compact_results_m)\n",
    "mov_w = margin_of_victory(regular_season_compact_results_w)\n",
    "\n",
    "print(mov_m.head())\n",
    "print(mov_w.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rating_system(df: pd.DataFrame, mov: pd.DataFrame) -> pd.DataFrame:\n",
    "    # The mov is passed in from the margin_of_victory function, so avg_MOV is already calculated\n",
    "    srs = mov.copy()\n",
    "\n",
    "    # We initialize the SRS to the average MOV\n",
    "    srs['SRS'] = srs['avg_MOV']\n",
    "\n",
    "    # We iteratively calculate the SRS until it converges\n",
    "    for i in range(100):\n",
    "        # Get opponents' SRS for games where team was winner\n",
    "        winner_sos = df.merge(srs[['Season', 'TeamID', 'SRS']], \n",
    "                             left_on=['Season', 'WTeamID'], \n",
    "                             right_on=['Season', 'TeamID'], \n",
    "                             how='left')\n",
    "        winner_sos = winner_sos.merge(srs[['Season', 'TeamID', 'SRS']], \n",
    "                                    left_on=['Season', 'LTeamID'], \n",
    "                                    right_on=['Season', 'TeamID'], \n",
    "                                    how='left',\n",
    "                                    suffixes=['_team', '_opp'])\n",
    "        \n",
    "        # Get opponents' SRS for games where team was loser\n",
    "        loser_sos = df.merge(srs[['Season', 'TeamID', 'SRS']], \n",
    "                            left_on=['Season', 'LTeamID'], \n",
    "                            right_on=['Season', 'TeamID'], \n",
    "                            how='left')\n",
    "        loser_sos = loser_sos.merge(srs[['Season', 'TeamID', 'SRS']], \n",
    "                                   left_on=['Season', 'WTeamID'], \n",
    "                                   right_on=['Season', 'TeamID'], \n",
    "                                   how='left',\n",
    "                                   suffixes=['_team', '_opp'])\n",
    "        \n",
    "        # Combine and calculate average opponent SRS\n",
    "        winner_opponents = winner_sos[['Season', 'TeamID_team', 'SRS_opp']].rename(\n",
    "            columns={'TeamID_team': 'TeamID'})\n",
    "        loser_opponents = loser_sos[['Season', 'TeamID_team', 'SRS_opp']].rename(\n",
    "            columns={'TeamID_team': 'TeamID'})\n",
    "        \n",
    "        all_opponents = pd.concat([winner_opponents, loser_opponents])\n",
    "        sos = all_opponents.groupby(['Season', 'TeamID'])['SRS_opp'].mean().reset_index()\n",
    "        sos.columns = ['Season', 'TeamID', 'SOS']\n",
    "\n",
    "        # Update SRS\n",
    "        srs = srs.merge(sos, on=['Season', 'TeamID'], how='left')\n",
    "        srs['SRS'] = srs['avg_MOV'] + srs['SOS']\n",
    "        srs.drop(columns=['SOS'], inplace=True)\n",
    "\n",
    "    return srs\n",
    "\n",
    "srs_m = simple_rating_system(regular_season_compact_results_m, mov_m)\n",
    "srs_w = simple_rating_system(regular_season_compact_results_w, mov_w)\n",
    "\n",
    "print(srs_m.head())\n",
    "print(srs_w.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now estimate possessions in order to derive Offensive Rating, Defensive Rating, and Net Rating.\n",
    "\n",
    "The formula for deriving possessions is Possessions = 0.96 \\times (FGA + TO + 0.44 \\times FTA - ORB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_ratings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Estimate possessions\n",
    "    df['WPossessions'] = 0.96 * (df['WFGA'] + df['WTO'] + 0.44 * df['WFTA'] - df['WOR'])\n",
    "    df['LPossessions'] = 0.96 * (df['LFGA'] + df['LTO'] + 0.44 * df['LFTA'] - df['LOR'])\n",
    "    \n",
    "    # Create dataframes for teams when they win\n",
    "    w_teams = df[['Season', 'WTeamID', 'WScore', 'LScore', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'WPossessions', 'LPossessions']].copy()\n",
    "    w_teams.columns = ['Season', 'TeamID', 'PointsScored', 'PointsAllowed', 'FGM', 'FGA', 'FGM3', 'FGA3', 'TFM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'OwnPossessions', 'OppPossessions']\n",
    "    \n",
    "    # Create dataframes for teams when they lose\n",
    "    l_teams = df[['Season', 'LTeamID', 'LScore', 'WScore', 'LPossessions', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', 'LPossessions', 'WPossessions']].copy()\n",
    "    l_teams.columns = ['Season', 'TeamID', 'PointsScored', 'PointsAllowed', 'FGM', 'FGA', 'FGM3', 'FGA3', 'TFM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'OwnPossessions', 'OppPossessions']\n",
    "    \n",
    "    # Combine both datasets\n",
    "    all_games = pd.concat([w_teams, l_teams])\n",
    "    \n",
    "    # Group by Season and TeamID to get all metrics\n",
    "    team_ratings = all_games.groupby(['Season', 'TeamID']).agg(\n",
    "        total_points_scored=('PointsScored', 'sum'),\n",
    "        total_points_allowed=('PointsAllowed', 'sum'),\n",
    "        total_field_goals_made=('FGM', 'sum'),\n",
    "        total_field_goals_attempted=('FGA', 'sum'),\n",
    "        total_three_point_field_goals_made=('FGM3', 'sum'),\n",
    "        total_three_point_field_goals_attempted=('FGA3', 'sum'),\n",
    "        total_free_throws_made=('TFM', 'sum'),\n",
    "        total_free_throws_attempted=('FTA', 'sum'),\n",
    "        total_offensive_rebounds=('OR', 'sum'),\n",
    "        total_defensive_rebounds=('DR', 'sum'),\n",
    "        total_assists=('Ast', 'sum'),\n",
    "        total_turnovers=('TO', 'sum'),\n",
    "        total_steals=('Stl', 'sum'),\n",
    "        total_blocks=('Blk', 'sum'),\n",
    "        total_PFs=('PF', 'sum'),\n",
    "        total_possessions=('OwnPossessions', 'sum'),\n",
    "        total_opp_possessions=('OppPossessions', 'sum'),\n",
    "        games_played=('PointsScored', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate advanced metrics\n",
    "    team_ratings['total_points_diff'] = team_ratings['total_points_scored'] - team_ratings['total_points_allowed']\n",
    "    team_ratings['points_per_game'] = team_ratings['total_points_scored'] / team_ratings['games_played']\n",
    "    team_ratings['field_goal_percentage'] = 100 * team_ratings['total_field_goals_made'] / team_ratings['total_field_goals_attempted']\n",
    "    team_ratings['field_goals_made_per_game'] = team_ratings['total_field_goals_made'] / team_ratings['games_played']\n",
    "    team_ratings['three_point_percentage'] = 100 * team_ratings['total_three_point_field_goals_made'] / team_ratings['total_three_point_field_goals_attempted']\n",
    "    team_ratings['three_point_field_goals_made_per_game'] = team_ratings['total_three_point_field_goals_made'] / team_ratings['games_played']\n",
    "    team_ratings['free_throw_percentage'] = 100 * team_ratings['total_free_throws_made'] / team_ratings['total_free_throws_attempted']\n",
    "    team_ratings['offensive_rebounds_per_game'] = team_ratings['total_offensive_rebounds'] / team_ratings['games_played']\n",
    "    team_ratings['defensive_rebounds_per_game'] = team_ratings['total_defensive_rebounds'] / team_ratings['games_played']\n",
    "    team_ratings['rebounds_per_game'] = team_ratings['offensive_rebounds_per_game'] + team_ratings['defensive_rebounds_per_game']\n",
    "    team_ratings['assists_per_game'] = team_ratings['total_assists'] / team_ratings['games_played']\n",
    "    team_ratings['turnovers_per_game'] = team_ratings['total_turnovers'] / team_ratings['games_played']\n",
    "    team_ratings['steals_per_game'] = team_ratings['total_steals'] / team_ratings['games_played']\n",
    "    team_ratings['blocks_per_game'] = team_ratings['total_blocks'] / team_ratings['games_played']\n",
    "    team_ratings['personal_fouls_per_game'] = team_ratings['total_PFs'] / team_ratings['games_played']\n",
    "    team_ratings['offensive_rating'] = 100 * team_ratings['total_points_scored'] / team_ratings['total_possessions']\n",
    "    team_ratings['defensive_rating'] = 100 * team_ratings['total_points_allowed'] / team_ratings['total_opp_possessions']\n",
    "    team_ratings['net_rating'] = team_ratings['offensive_rating'] - team_ratings['defensive_rating']\n",
    "    \n",
    "    return team_ratings\n",
    "\n",
    "ratings_m = advanced_ratings(regular_season_detailed_results_m)\n",
    "ratings_w = advanced_ratings(regular_season_detailed_results_w)\n",
    "\n",
    "print(ratings_m.head())\n",
    "print(ratings_w.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we need to start narrowing down the variables of interest.\n",
    "Here are the ones we will include:\n",
    "- Season\n",
    "- TeamID\n",
    "- ConfAbbrev\n",
    "- offensive_rating\n",
    "- defensive_rating\n",
    "- net_rating\n",
    "- win_pct\n",
    "- Seed\n",
    "- Seed Difference\n",
    "- rebounds_per_game\n",
    "- assists_per_game\n",
    "- steals_per_game\n",
    "- blocks_per_game\n",
    "- turnovers_per_game\n",
    "- personal_fouls_per_game\n",
    "- field_goal_percentage\n",
    "- field_goals_made_per_game\n",
    "- three_point_percentage\n",
    "- three_point_field_goals_made_per_game\n",
    "- total_points_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_conference(df: pd.DataFrame, conferences: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.merge(conferences, on=['TeamID', 'Season'], how='left')\n",
    "    return df\n",
    "\n",
    "ratings_m = get_team_conference(ratings_m, conferences_m)\n",
    "ratings_w = get_team_conference(ratings_w, conferences_w)\n",
    "\n",
    "def get_seed_difference(df: pd.DataFrame, seeding: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.merge(seeding, on=['TeamID', 'Season'], how='left')\n",
    "    return df\n",
    "\n",
    "ratings_m = get_seed(ratings_m, seeding_by_season_m)\n",
    "ratings_w = get_seed(ratings_w, seeding_by_season_w)\n",
    "\n",
    "def drop_unnecessary_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns = ['total_points_allowed', 'total_field_goals_made', 'total_field_goals_attempted', \n",
    "               'total_three_point_field_goals_made', 'total_three_point_field_goals_attempted', 'total_free_throws_made', \n",
    "               'total_free_throws_attempted', 'total_offensive_rebounds', 'total_defensive_rebounds', 'total_assists', \n",
    "               'total_turnovers', 'total_steals', 'total_blocks', 'total_PFs', 'total_possessions', \n",
    "               'total_opp_possessions', 'games_played']\n",
    "    df.drop(columns=columns, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Drop unnecessary columns\n",
    "ratings_m = drop_unnecessary_columns(ratings_m)\n",
    "ratings_w = drop_unnecessary_columns(ratings_w)\n",
    "\n",
    "print(ratings_m.head())\n",
    "print(ratings_w.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we can start to build the model using XGBoost.\n",
    "The dataframes ratings_m and ratings_w should have all the relevant data we need to build the model.\n",
    "But the model will need to be able to take in as input all possible matchups between two regular season teams in each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "# xgboost related libraries:\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# sklearn related libraries:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting up the data\n",
    "\n",
    "y_actual_m = pd.read_csv(\"/kaggle/input/march-madness-2025/MNCAATourneyCompactResults.csv\")\n",
    "y_actual_w = pd.read_csv(\"/kaggle/input/march-madness-2025/WNCAATourneyCompactResults.csv\")\n",
    "\n",
    "base_data_m = ratings_m.copy()\n",
    "base_data_w = ratings_w.copy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_actual needs to be augmented to include all possible matchups. If a matchup is not in the tourney results, then WScore will be total points scored by the winning team and LScore will be total points scored by the losing team.\n",
    "This is because the target variable is a float with range [0,1] that predicts the probability of the winning team winning the matchup.\n",
    "We'll have to use point spread to determine the target variable. Calculations should be based on betting line conventions.\n",
    "If two teams are in the tournamenet, then the target variable will be a sigmoid curve with a mean of 0.5 and a standard deviation of 0.1. \n",
    "The curve will be shifted to the right if the higher seed is the winning team and to the left if the lower seed is the winning team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to reshape the data so that all possible matchups are included in the data. This will be done by creating a new dataframe that includes all possible matchups between two teams in each season.\n",
    "\n",
    "def create_all_matchups(ratings_df):\n",
    "    \"\"\"\n",
    "    Create all possible matchups between teams for each season,\n",
    "    ensuring no duplicates (TeamA vs TeamB and TeamB vs TeamA)\n",
    "    \"\"\"\n",
    "    # List to store all matchups\n",
    "    all_matchups = []\n",
    "    \n",
    "    # For each season\n",
    "    for season in ratings_df['Season'].unique():\n",
    "        # Get teams for this season\n",
    "        season_teams = ratings_df[ratings_df['Season'] == season]['TeamID'].tolist()\n",
    "        \n",
    "        # Create all possible matchups where TeamID1 < TeamID2 to avoid duplicates\n",
    "        for i, team1 in enumerate(season_teams):\n",
    "            for team2 in season_teams[i+1:]:\n",
    "                all_matchups.append({'Season': season, 'TeamID1': team1, 'TeamID2': team2})\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    matchups_df = pd.DataFrame(all_matchups)\n",
    "    \n",
    "    return matchups_df\n",
    "\n",
    "# Create all possible matchups for men's and women's teams\n",
    "matchups_m = create_all_matchups(ratings_m)\n",
    "matchups_w = create_all_matchups(ratings_w)\n",
    "\n",
    "print(f\"Number of men's matchups: {len(matchups_m)}\")\n",
    "print(f\"Number of women's matchups: {len(matchups_w)}\")\n",
    "print(matchups_m.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to fill in the target values for all possible combinations.\n",
    "The formula involves the game's point spread (if available), the seed difference between 2 teams (if available), the difference in net rating between the 2 teams, and the difference in SRS between the two teams.\n",
    "The evaluation method uses the Brier Score, which is used by the Kaggle competition to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_tourney_results(df: pd.DataFrame, tourney_results: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function isn't the final model. It's just meant to fill in the target variable.\n",
    "    \"\"\"\n",
    "\n",
    "    # Let's merge the matchups with the actual tournament results, we need to preserve all hypothetical matchups\n",
    "    # First, standardize the tournament results to match our matchup format\n",
    "    # Create a copy of tournament_results\n",
    "    tourney_std = tourney_results.copy()\n",
    "    \n",
    "    # Ensure WTeamID and LTeamID are integers\n",
    "    tourney_std['WTeamID'] = tourney_std['WTeamID'].astype(int)\n",
    "    tourney_std['LTeamID'] = tourney_std['LTeamID'].astype(int)\n",
    "\n",
    "    # Create columns to match our standardized format where TeamID1 < TeamID2\n",
    "    tourney_std['TeamID1'] = tourney_std.apply(lambda row: min(row['WTeamID'], row['LTeamID']), axis=1)\n",
    "    tourney_std['TeamID2'] = tourney_std.apply(lambda row: max(row['WTeamID'], row['LTeamID']), axis=1)\n",
    "    \n",
    "    # Add a column to track whether TeamID1 was the winner\n",
    "    tourney_std['TeamID1_Won'] = tourney_std['TeamID1'] == tourney_std['WTeamID']\n",
    "\n",
    "    # Add a data source column to identify the source of each result\n",
    "    tourney_std['DataSource'] = 'Tournament'\n",
    "\n",
    "    # Select only the columns we need from tourney_std\n",
    "    tourney_cols = ['Season', 'TeamID1', 'TeamID2', 'TeamID1_Won', 'WScore', 'LScore', 'DataSource']\n",
    "    tourney_subset = tourney_std[tourney_cols]\n",
    "    \n",
    "    # Merge with our matchups dataframe\n",
    "    result_df = df.merge(tourney_subset, on=['Season', 'TeamID1', 'TeamID2'], how='right')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "y_actual_m = tournament_detailed_results_m\n",
    "y_actual_w = tournament_detailed_results_w\n",
    "\n",
    "merged_tourney_df_m = fill_in_tourney_results(matchups_m, y_actual_m)\n",
    "merged_tourney_df_w = fill_in_tourney_results(matchups_w, y_actual_w)\n",
    "\n",
    "display(merged_tourney_df_m)\n",
    "display(merged_tourney_df_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_regular_results(df: pd.DataFrame, regular_results: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # We need to fill in the regular season matchups where the tournament results are missing\n",
    "    regular_std = regular_results.copy()\n",
    "\n",
    "    # Ensure WTeamID and LTeamID are integers\n",
    "    regular_std['WTeamID'] = regular_std['WTeamID'].astype(int)\n",
    "    regular_std['LTeamID'] = regular_std['LTeamID'].astype(int)\n",
    "\n",
    "    # Create columns to match our standardized format where TeamID1 < TeamID2\n",
    "    regular_std['TeamID1'] = regular_std.apply(lambda row: min(row['WTeamID'], row['LTeamID']), axis=1)\n",
    "    regular_std['TeamID2'] = regular_std.apply(lambda row: max(row['WTeamID'], row['LTeamID']), axis=1)\n",
    "\n",
    "    # Add a column to track whether TeamID1 was the winner, astype int to convert boolean to 0 or 1\n",
    "    regular_std['TeamID1_Won'] = (regular_std['TeamID1'] == regular_std['WTeamID']).astype(int)\n",
    "    \n",
    "    # Add a column to identify this as regular season data\n",
    "    regular_std['DataSource'] = 'RegularSeason'\n",
    "    \n",
    "    # Select only the columns we need from regular_std\n",
    "    regular_cols = ['Season', 'TeamID1', 'TeamID2', 'TeamID1_Won', 'WScore', 'LScore', 'DataSource']\n",
    "    regular_subset = regular_std[regular_cols]\n",
    "        \n",
    "    # Merge with dataframe but only keep rows that exist in regular_subset\n",
    "    result_df = df.merge(regular_subset, on=['Season', 'TeamID1', 'TeamID2'], how='right')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "    # # Fill in the target variable\n",
    "    # # The target variable is a function of the game's point spread, the seed difference, and the difference in net rating between the two teams\n",
    "    # # The point spread is the difference in points scored between the winning and losing teams, the bigger the point spread, the more likely the winning team is to win\n",
    "    # # The seed difference is the difference in seed between the two teams, the bigger the seed difference, the more likely the higher seed is to win\n",
    "    # # The difference in net rating is the difference in net rating between the two teams, the bigger the difference, the more likely the team with the higher net rating is to win\n",
    "    # # Target has a range of [0,1], thus a sigmoid function is used to normalize the target variable\n",
    "    # df['target'] = 1 / (1 + np.exp(-0.1 * (df['MOV'] - 0.1 * df['seed_diff'] - 0.1 * df['net_rating_diff'] - 0.1 * df['srs_diff'])))\n",
    "\n",
    "    # return df\n",
    "\n",
    "merged_regular_df_m = fill_in_regular_results(matchups_m, regular_season_detailed_results_m)\n",
    "\n",
    "display(merged_regular_df_m)\n",
    "\n",
    "merged_regular_df_w = fill_in_regular_results(matchups_w, regular_season_detailed_results_w)\n",
    "\n",
    "display(merged_regular_df_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_other_results(df: pd.DataFrame, tourney_results: pd.DataFrame, regular_results: pd.DataFrame, ratings: pd.DataFrame, srs: pd.DataFrame, alpha=0.1) -> pd.DataFrame:\n",
    "    # Filter our the rows in df that already exist in tourney_results and regular_results\n",
    "    # They key is TeamID1, TeamID2, and Season\n",
    "\n",
    "    tourney_results_rows = tourney_results[['Season', 'TeamID1', 'TeamID2']].copy()\n",
    "    regular_results_rows = regular_results[['Season', 'TeamID1', 'TeamID2']].copy()\n",
    "\n",
    "    existing_results = pd.concat([tourney_results_rows, regular_results_rows])\n",
    "\n",
    "    # Filter out existing_results from df\n",
    "    # Merge with indicator to identify rows that exist only in df\n",
    "\n",
    "    df = df.merge(existing_results, on=['Season', 'TeamID1', 'TeamID2'], how='left', indicator=True)\n",
    "\n",
    "    # Keep only rows that are in df but not in existing_results\n",
    "    df = df[df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "    # For the remaining rows, create columns TeamID1_Won, WScore, LScore, DataSource\n",
    "    # WScore is the points per game for the winning team for the season\n",
    "    # LScore is the points per game for the losing team for the season\n",
    "    # DataSource is 'Other'\n",
    "    # TeamID1_Won is 1 if TeamID1 has a higher points per game than TeamID2, 0 otherwise\n",
    "\n",
    "    # Merge with ratings to get points per game for each team\n",
    "    ratings_subset = ratings[['Season', 'TeamID', 'points_per_game']]\n",
    "\n",
    "    df = df.merge(ratings_subset, left_on=['Season', 'TeamID1'], right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    df.rename(columns={'points_per_game': 'Team1_PPG'}, inplace=True)\n",
    "\n",
    "    df = df.merge(ratings_subset, left_on=['Season', 'TeamID2'], right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    df.rename(columns={'points_per_game': 'Team2_PPG'}, inplace=True)\n",
    "\n",
    "    # We need to adjust the Team1_PPG and Team2_PPG columns by SRS, which is a measure of team strength\n",
    "    # The higher the SRS, the stronger the team\n",
    "    # We will adjust the points per game by the SRS\n",
    "\n",
    "    srs_subset = srs[['Season', 'TeamID', 'SRS']]\n",
    "    df = df.merge(srs_subset, left_on=['Season', 'TeamID1'], right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    drop_columns = ['TeamID_x', 'TeamID_y', 'TeamID']\n",
    "\n",
    "    df.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "    df = df.merge(srs_subset, left_on=['Season', 'TeamID2'], right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    drop_columns = ['TeamID']\n",
    "\n",
    "    df.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "    df.rename(columns={'SRS_x': 'Team1_SRS', 'SRS_y': 'Team2_SRS'}, inplace=True)\n",
    "\n",
    "    # First, calculate the difference in SRS betweeen the two teams, with a greater difference indicating a stronger team\n",
    "    df['SRS_diff'] = df['Team1_SRS'] - df['Team2_SRS']\n",
    "    df['SRS_scaled'] = 2 / (1 + np.exp(-alpha * df['SRS_diff']))\n",
    "    df['Expected_PPG1'] = df['Team1_PPG'] * df['SRS_scaled']\n",
    "    df['Expected_PPG2'] = df['Team2_PPG'] * (2 - df['SRS_scaled'])\n",
    "\n",
    "\n",
    "    # Create TeamID_Won, WScore, LScore, and DataSource columns\n",
    "    df['TeamID1_Won'] = (df['Expected_PPG1'] > df['Expected_PPG2']).astype(int)\n",
    "    df['WScore'] = df['Expected_PPG1']\n",
    "    df['LScore'] = df['Expected_PPG2']\n",
    "    df['DataSource'] = 'Other'\n",
    "\n",
    "    # Round the scores to integers\n",
    "    df['WScore'] = df['WScore'].round().astype(int)\n",
    "    df['LScore'] = df['LScore'].round().astype(int)\n",
    "\n",
    "    print(df.columns)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=['Team1_PPG', 'Team2_PPG', 'Team1_SRS', 'Team2_SRS', 'SRS_diff', 'SRS_scaled','Expected_PPG1', 'Expected_PPG2'], inplace=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "merged_other_df_m = fill_in_other_results(matchups_m, merged_tourney_df_m, merged_regular_df_m, base_data_m, srs_m, alpha=0.006)\n",
    "display(merged_other_df_m)\n",
    "\n",
    "# # Show rows where (TeamID1 is in the bottom 10% of SRS and TeamID2 is in the top 10% of SRS) or (TeamID1 is in the top 10% of SRS and TeamID2 is in the bottom 10% of SRS)\n",
    "# top_bottom_matchups_m = merged_other_df_m[\n",
    "#     ((merged_other_df_m['Team1_SRS'] < merged_other_df_m['Team1_SRS'].quantile(0.1)) & \n",
    "#      (merged_other_df_m['Team2_SRS'] > merged_other_df_m['Team2_SRS'].quantile(0.9))) | \n",
    "#     ((merged_other_df_m['Team1_SRS'] > merged_other_df_m['Team1_SRS'].quantile(0.9)) & \n",
    "#      (merged_other_df_m['Team2_SRS'] < merged_other_df_m['Team2_SRS'].quantile(0.1)))\n",
    "# ]\n",
    "\n",
    "# display(top_bottom_matchups_m)\n",
    "\n",
    "# # Find the average point spread (absolute value) for these matchups, which is the difference in points per game between the two teams\n",
    "# avg_point_spread_m = top_bottom_matchups_m['WScore'].sub(top_bottom_matchups_m['LScore']).abs().mean()\n",
    "# print(f\"Average point spread for top 10% vs bottom 10% matchups: {avg_point_spread_m:.2f}\")\n",
    "\n",
    "# Average point spread for top 10% vs bottom 10% matchups: 26.34\n",
    "\n",
    "merged_other_df_w = fill_in_other_results(matchups_w, merged_tourney_df_w, merged_regular_df_w, base_data_w, srs_w, alpha=0.007)\n",
    "display(merged_other_df_w)\n",
    "\n",
    "# # Show rows where (TeamID1 is in the bottom 10% of SRS and TeamID2 is in the top 10% of SRS) or (TeamID1 is in the top 10% of SRS and TeamID2 is in the bottom 10% of SRS)\n",
    "# top_bottom_matchups_w = merged_other_df_w[\n",
    "#     ((merged_other_df_w['Team1_SRS'] < merged_other_df_w['Team1_SRS'].quantile(0.1)) & \n",
    "#      (merged_other_df_w['Team2_SRS'] > merged_other_df_w['Team2_SRS'].quantile(0.9))) | \n",
    "#     ((merged_other_df_w['Team1_SRS'] > merged_other_df_w['Team1_SRS'].quantile(0.9)) & \n",
    "#      (merged_other_df_w['Team2_SRS'] < merged_other_df_w['Team2_SRS'].quantile(0.1)))\n",
    "# ]\n",
    "\n",
    "# display(top_bottom_matchups_m)\n",
    "\n",
    "# # Find the average point spread (absolute value) for these matchups, which is the difference in points per game between the two teams\n",
    "# avg_point_spread_w = top_bottom_matchups_w['WScore'].sub(top_bottom_matchups_w['LScore']).abs().mean()\n",
    "# print(f\"Average point spread for top 10% vs bottom 10% matchups: {avg_point_spread_w:.2f}\")\n",
    "\n",
    "# Average point spread for top 10% vs bottom 10% matchups: 40.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_results(tourney_df: pd.DataFrame, regular_df: pd.DataFrame, other_df: pd.DataFrame, ratings: pd.DataFrame, srs: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Note that if a Season, TeamID1, TeamID2 combination exists in multiple dataframes, the order of precedence is tourney_df, regular_df, other_df\n",
    "    # This means that if a row exists in tourney_df, it will be kept, and the same for regular_df and other_df\n",
    "\n",
    "    merged_df = tourney_df.merge(regular_df, on=['Season', 'TeamID1', 'TeamID2'], how='outer', suffixes=('_tourney', '_regular'))\n",
    "    \n",
    "    # Handle precedence - tournament results take priority\n",
    "    # First, create columns without suffixes using tournament data when available, regular data otherwise\n",
    "    for col in ['TeamID1_Won', 'WScore', 'LScore', 'DataSource']:\n",
    "        merged_df[col] = merged_df[f'{col}_tourney'].combine_first(merged_df[f'{col}_regular'])\n",
    "    \n",
    "    # Drop the columns with suffixes as we've consolidated them\n",
    "    cols_to_drop = [col for col in merged_df.columns if col.endswith('_tourney') or col.endswith('_regular')]\n",
    "    merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Now merge with other results, again with other having lowest precedence\n",
    "    merged_df = merged_df.merge(other_df, on=['Season', 'TeamID1', 'TeamID2'], how='outer', suffixes=('', '_other'))\n",
    "    \n",
    "    # Again handle precedence - merged results take priority over other\n",
    "    for col in ['TeamID1_Won', 'WScore', 'LScore', 'DataSource']:\n",
    "        if f'{col}_other' in merged_df.columns:\n",
    "            merged_df[col] = merged_df[col].combine_first(merged_df[f'{col}_other'])\n",
    "    \n",
    "    # Drop the columns with _other suffix\n",
    "    cols_to_drop = [col for col in merged_df.columns if col.endswith('_other')]\n",
    "    merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    display(merged_df)\n",
    "\n",
    "    # Merge with ratings and SRS data for team statistics\n",
    "    ratings_team1 = ratings.copy()\n",
    "    for col in ratings_team1.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            ratings_team1.rename(columns={col: f\"{col}_team1\"}, inplace=True)\n",
    "    \n",
    "    # Merge with explicitly renamed columns to avoid suffix issues\n",
    "    merged_df = merged_df.merge(ratings_team1, left_on=['Season', 'TeamID1'], \n",
    "                              right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    display(merged_df)\n",
    "    \n",
    "    ratings_team2 = ratings.copy()\n",
    "    for col in ratings_team2.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            ratings_team2.rename(columns={col: f\"{col}_team2\"}, inplace=True)\n",
    "    \n",
    "    merged_df = merged_df.merge(ratings_team2, left_on=['Season', 'TeamID2'], \n",
    "                              right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    display(merged_df)\n",
    "    \n",
    "    srs_team1 = srs.copy()\n",
    "    for col in srs_team1.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            srs_team1.rename(columns={col: f\"{col}_team1\"}, inplace=True)\n",
    "    \n",
    "    merged_df = merged_df.merge(srs_team1, left_on=['Season', 'TeamID1'], \n",
    "                              right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    display(merged_df)\n",
    "    \n",
    "    srs_team2 = srs.copy()\n",
    "    for col in srs_team2.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            srs_team2.rename(columns={col: f\"{col}_team2\"}, inplace=True)\n",
    "    \n",
    "    merged_df = merged_df.merge(srs_team2, left_on=['Season', 'TeamID2'], \n",
    "                              right_on=['Season', 'TeamID'], how='left', suffixes=('', '_srs2'))\n",
    "\n",
    "    display(merged_df)\n",
    "\n",
    "    # Scan for duplicate Season, TeamID1, TeamID2, and drop duplicates per the tourney, regular, other precedence\n",
    "    merged_df = merged_df.drop_duplicates(subset=['Season', 'TeamID1', 'TeamID2'], keep='first')\n",
    "\n",
    "    print(merged_df.columns)\n",
    "    \n",
    "    # Fill missing seeds based on closest SRS value within the same season\n",
    "    for season in merged_df['Season'].unique():\n",
    "        season_mask = merged_df['Season'] == season\n",
    "        \n",
    "        # Handle team1 seeds\n",
    "        known_seed_mask1 = merged_df['seed_team1'].notna()\n",
    "        known_seed_data1 = merged_df[season_mask & known_seed_mask1].copy()\n",
    "        \n",
    "        if not known_seed_data1.empty:\n",
    "            missing_seed_mask1 = merged_df['seed_team1'].isna()\n",
    "            missing_seed_data1 = merged_df[season_mask & missing_seed_mask1]\n",
    "            \n",
    "            for idx, row in missing_seed_data1.iterrows():\n",
    "                if pd.isna(row['SRS_team1']):\n",
    "                    # If SRS is also missing, use default value\n",
    "                    merged_df.loc[idx, 'seed_team1'] = 20\n",
    "                else:\n",
    "                    # Find seed of team with closest SRS value\n",
    "                    known_seed_data1['srs_diff'] = abs(known_seed_data1['SRS_team1'] - row['SRS_team1'])\n",
    "                    closest_idx = known_seed_data1['srs_diff'].idxmin()\n",
    "                    merged_df.loc[idx, 'seed_team1'] = merged_df.loc[closest_idx, 'seed_team1']\n",
    "        else:\n",
    "            # No teams with seeds in this season, use default\n",
    "            merged_df.loc[season_mask & merged_df['seed_team1'].isna(), 'seed_team1'] = 20\n",
    "        \n",
    "        # Handle team2 seeds using the same approach\n",
    "        known_seed_mask2 = merged_df['seed_team2'].notna()\n",
    "        known_seed_data2 = merged_df[season_mask & known_seed_mask2].copy()\n",
    "        \n",
    "        if not known_seed_data2.empty:\n",
    "            missing_seed_mask2 = merged_df['seed_team2'].isna()\n",
    "            missing_seed_data2 = merged_df[season_mask & missing_seed_mask2]\n",
    "            \n",
    "            for idx, row in missing_seed_data2.iterrows():\n",
    "                if pd.isna(row['SRS_team2']):\n",
    "                    merged_df.loc[idx, 'seed_team2'] = 20\n",
    "                else:\n",
    "                    known_seed_data2['srs_diff'] = abs(known_seed_data2['SRS_team2'] - row['SRS_team2'])\n",
    "                    closest_idx = known_seed_data2['srs_diff'].idxmin()\n",
    "                    merged_df.loc[idx, 'seed_team2'] = merged_df.loc[closest_idx, 'seed_team2']\n",
    "        else:\n",
    "            merged_df.loc[season_mask & merged_df['seed_team2'].isna(), 'seed_team2'] = 20\n",
    "\n",
    "    dropped_columns = ['TeamID_x', 'total_points_scored_team1', 'TeamID_y', 'total_points_scored_team2']\n",
    "\n",
    "    merged_df.drop(columns=dropped_columns, inplace=True)\n",
    "\n",
    "\n",
    "    # Target variable will be 1 if TeamID1 wins, 0 otherwise\n",
    "    merged_df.rename(columns={'TeamID1_Won': 'target'}, inplace=True)\n",
    "\n",
    "    # Move target to the last column\n",
    "    cols = list(merged_df.columns)\n",
    "    cols.remove('target')\n",
    "    merged_df = merged_df[cols + ['target']]\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "    \n",
    "combined_df_m = merge_all_results(merged_tourney_df_m, merged_regular_df_m, merged_other_df_m, ratings_m, srs_m)\n",
    "display(combined_df_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_results_w(tourney_df: pd.DataFrame, regular_df: pd.DataFrame, other_df: pd.DataFrame, ratings: pd.DataFrame, srs: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Note that if a Season, TeamID1, TeamID2 combination exists in multiple dataframes, the order of precedence is tourney_df, regular_df, other_df\n",
    "    # This means that if a row exists in tourney_df, it will be kept, and the same for regular_df and other_df\n",
    "\n",
    "    merged_df = tourney_df.merge(regular_df, on=['Season', 'TeamID1', 'TeamID2'], how='outer', suffixes=('_tourney', '_regular'))\n",
    "    \n",
    "    # Handle precedence - tournament results take priority\n",
    "    # First, create columns without suffixes using tournament data when available, regular data otherwise\n",
    "    for col in ['TeamID1_Won', 'WScore', 'LScore', 'DataSource']:\n",
    "        merged_df[col] = merged_df[f'{col}_tourney'].combine_first(merged_df[f'{col}_regular'])\n",
    "    \n",
    "    # Drop the columns with suffixes as we've consolidated them\n",
    "    cols_to_drop = [col for col in merged_df.columns if col.endswith('_tourney') or col.endswith('_regular')]\n",
    "    merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Now merge with other results, again with other having lowest precedence\n",
    "    merged_df = merged_df.merge(other_df, on=['Season', 'TeamID1', 'TeamID2'], how='outer', suffixes=('', '_other'))\n",
    "    \n",
    "    # Again handle precedence - merged results take priority over other\n",
    "    for col in ['TeamID1_Won', 'WScore', 'LScore', 'DataSource']:\n",
    "        if f'{col}_other' in merged_df.columns:\n",
    "            merged_df[col] = merged_df[col].combine_first(merged_df[f'{col}_other'])\n",
    "    \n",
    "    # Drop the columns with _other suffix\n",
    "    cols_to_drop = [col for col in merged_df.columns if col.endswith('_other')]\n",
    "    merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    display(merged_df)\n",
    "\n",
    "    # Merge with ratings and SRS data for team statistics\n",
    "    ratings_team1 = ratings.copy()\n",
    "    for col in ratings_team1.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            ratings_team1.rename(columns={col: f\"{col}_team1\"}, inplace=True)\n",
    "    \n",
    "    # Merge with explicitly renamed columns to avoid suffix issues\n",
    "    merged_df = merged_df.merge(ratings_team1, left_on=['Season', 'TeamID1'], \n",
    "                              right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    display(merged_df)\n",
    "    \n",
    "    ratings_team2 = ratings.copy()\n",
    "    for col in ratings_team2.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            ratings_team2.rename(columns={col: f\"{col}_team2\"}, inplace=True)\n",
    "    \n",
    "    merged_df = merged_df.merge(ratings_team2, left_on=['Season', 'TeamID2'], \n",
    "                              right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    display(merged_df)\n",
    "    \n",
    "    srs_team1 = srs.copy()\n",
    "    for col in srs_team1.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            srs_team1.rename(columns={col: f\"{col}_team1\"}, inplace=True)\n",
    "    \n",
    "    merged_df = merged_df.merge(srs_team1, left_on=['Season', 'TeamID1'], \n",
    "                              right_on=['Season', 'TeamID'], how='left')\n",
    "\n",
    "    display(merged_df)\n",
    "    \n",
    "    srs_team2 = srs.copy()\n",
    "    for col in srs_team2.columns:\n",
    "        if col not in ['Season', 'TeamID']:\n",
    "            srs_team2.rename(columns={col: f\"{col}_team2\"}, inplace=True)\n",
    "    \n",
    "    merged_df = merged_df.merge(srs_team2, left_on=['Season', 'TeamID2'], \n",
    "                              right_on=['Season', 'TeamID'], how='left', suffixes=('', '_srs2'))\n",
    "\n",
    "    display(merged_df)\n",
    "\n",
    "    # Scan for duplicate Season, TeamID1, TeamID2, and drop duplicates per the tourney, regular, other precedence\n",
    "    merged_df = merged_df.drop_duplicates(subset=['Season', 'TeamID1', 'TeamID2'], keep='first')\n",
    "\n",
    "    print(merged_df.columns)\n",
    "    \n",
    "    # Fill missing seeds based on closest SRS value within the same season\n",
    "    for season in merged_df['Season'].unique():\n",
    "        season_mask = merged_df['Season'] == season\n",
    "        \n",
    "        # Handle team1 seeds\n",
    "        known_seed_mask1 = merged_df['seed_team1'].notna()\n",
    "        known_seed_data1 = merged_df[season_mask & known_seed_mask1].copy()\n",
    "        \n",
    "        if not known_seed_data1.empty:\n",
    "            missing_seed_mask1 = merged_df['seed_team1'].isna()\n",
    "            missing_seed_data1 = merged_df[season_mask & missing_seed_mask1]\n",
    "            \n",
    "            for idx, row in missing_seed_data1.iterrows():\n",
    "                if pd.isna(row['SRS_team1']):\n",
    "                    # If SRS is also missing, use default value\n",
    "                    merged_df.loc[idx, 'seed_team1'] = 20\n",
    "                else:\n",
    "                    # Find seed of team with closest SRS value\n",
    "                    known_seed_data1['srs_diff'] = abs(known_seed_data1['SRS_team1'] - row['SRS_team1'])\n",
    "                    closest_idx = known_seed_data1['srs_diff'].idxmin()\n",
    "                    merged_df.loc[idx, 'seed_team1'] = merged_df.loc[closest_idx, 'seed_team1']\n",
    "        else:\n",
    "            # No teams with seeds in this season, use default\n",
    "            merged_df.loc[season_mask & merged_df['seed_team1'].isna(), 'seed_team1'] = 20\n",
    "        \n",
    "        # Handle team2 seeds using the same approach\n",
    "        known_seed_mask2 = merged_df['seed_team2'].notna()\n",
    "        known_seed_data2 = merged_df[season_mask & known_seed_mask2].copy()\n",
    "        \n",
    "        if not known_seed_data2.empty:\n",
    "            missing_seed_mask2 = merged_df['seed_team2'].isna()\n",
    "            missing_seed_data2 = merged_df[season_mask & missing_seed_mask2]\n",
    "            \n",
    "            for idx, row in missing_seed_data2.iterrows():\n",
    "                if pd.isna(row['SRS_team2']):\n",
    "                    merged_df.loc[idx, 'seed_team2'] = 20\n",
    "                else:\n",
    "                    known_seed_data2['srs_diff'] = abs(known_seed_data2['SRS_team2'] - row['SRS_team2'])\n",
    "                    closest_idx = known_seed_data2['srs_diff'].idxmin()\n",
    "                    merged_df.loc[idx, 'seed_team2'] = merged_df.loc[closest_idx, 'seed_team2']\n",
    "        else:\n",
    "            merged_df.loc[season_mask & merged_df['seed_team2'].isna(), 'seed_team2'] = 20\n",
    "\n",
    "    dropped_columns = ['TeamID_x', 'total_points_scored_team1', 'TeamID_y', 'total_points_scored_team2']\n",
    "\n",
    "    merged_df.drop(columns=dropped_columns, inplace=True)\n",
    "\n",
    "\n",
    "    # Target variable will be 1 if TeamID1 wins, 0 otherwise\n",
    "    merged_df.rename(columns={'TeamID1_Won': 'target'}, inplace=True)\n",
    "\n",
    "    # Move target to the last column\n",
    "    cols = list(merged_df.columns)\n",
    "    cols.remove('target')\n",
    "    merged_df = merged_df[cols + ['target']]\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# print(matchups_w.shape)\n",
    "# print(ratings_w.columns)\n",
    "# print(srs_w.columns)\n",
    "\n",
    "# print(merged_tourney_df_w.head())\n",
    "# print(ratings_w.head())\n",
    "# print(srs_w.head())\n",
    "\n",
    "combined_df_w = merge_all_results_w(merged_tourney_df_w, merged_regular_df_w, merged_other_df_w, ratings_w, srs_w)\n",
    "display(combined_df_w)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
